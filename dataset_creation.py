import pandas as pd

# Define keywords and their corresponding CPU, GPU, TPU values
keywords = [
    ('default',1,0,0),
    ('import', 1, 0, 0),
    ('CNN', 0, 1, 1),
    ('RNN', 1, 0, 1),
    ('preprocess', 1, 1, 0),
    ('train', 0, 1, 1),
    ('eval', 1, 0, 0),
    ('transfer', 0, 1, 1),
    ('feature', 1, 1, 0),
    ('tune', 1, 0, 0),
    ('grid', 1, 0, 0),
    ('LSTM', 1, 0, 1),
    ('data_augmentation', 1, 1, 0),
    ('batch_normalization', 0, 1, 1),
    ('dropout', 1, 0, 0),
    ('optimization', 1, 1, 1),
    ('model_saving', 1, 0, 0),
    ('hyperparameter_search', 1, 1, 0),
    ('data_loading', 1, 1, 0),
    ('evaluation_metrics', 1, 0, 0),
    ('fine_tuning', 0, 1, 1),
    ('ensemble_learning', 1, 1, 0),
    ('tokenization', 1, 0, 0),
    ('backpropagation', 1, 0, 0),
    ('regularization', 1, 0, 0),
    ('transfer_learning', 0, 1, 1),
    ('seq2seq', 1, 0, 1),
    ('attention_mechanism', 0, 1, 1),
    ('model_export', 1, 0, 0),
    ('real_time_inference', 0, 1, 1),
    ('predictive_analysis', 1, 0, 0),
    ('class_weighting', 1, 1, 0),
    ('grid_search_cv', 1, 0, 0),
    ('cross_validation', 1, 1, 0),
    ('feature_scaling', 1, 1, 0),
    ('loss_function', 1, 0, 0),
    ('convolutional_layer', 0, 1, 1),
    ('pooling_layer', 0, 1, 0),
    ('output_layer', 1, 0, 0),
    ('activation_function', 1, 0, 0),
    ('parameter_tuning', 1, 1, 1),
    ('data_split', 1, 0, 0),
    ('model_validation', 1, 1, 0),
    ('neural_network', 1, 0, 1),
    ('autoencoder', 1, 0, 1),
    ('multilayer_perceptron', 1, 0, 0),
    ('k_fold_cv', 1, 1, 0),
    ('pipeline', 1, 1, 0),
    ('data_normalization', 1, 1, 0),
    ('sampling', 1, 1, 0),
    ('label_encoding', 1, 0, 0),
    ('one_hot_encoding', 1, 1, 0),
    ('dimensionality_reduction', 1, 1, 0),
    ('feature_selection', 1, 0, 0),
    ('model_ensemble', 1, 1, 0),
    ('gradient_descent', 1, 0, 0),
    ('stochastic_gradient_descent', 1, 0, 0),
    ('momentum', 1, 0, 0),
    ('learning_rate_schedule', 1, 1, 0),
    ('early_stopping', 1, 0, 0),
    ('loss_backpropagation', 1, 0, 0),
    ('training_epochs', 1, 0, 0),
    ('predict', 1, 0, 0),
    ('confusion_matrix', 1, 0, 0),
    ('roc_curve', 1, 0, 0),
    ('precision_recall', 1, 0, 0),
    ('hyperparameter_tuning', 1, 1, 0),
    ('cross_entropy', 1, 0, 0),
    ('binary_crossentropy', 1, 0, 0),
    ('categorical_crossentropy', 1, 0, 0),
    ('sparse_categorical_crossentropy', 1, 0, 0),
    ('focal_loss', 1, 0, 0),
    ('adam_optimizer', 1, 1, 1),
    ('sgd_optimizer', 1, 0, 0),
    ('rmsprop_optimizer', 1, 1, 1),
    ('learning_rate', 1, 1, 0),
    ('data_generator', 1, 1, 0),
    ('image_processing', 1, 1, 0),
    ('text_processing', 1, 0, 0),
    ('time_series_analysis', 1, 0, 0),
    ('feature_importance', 1, 1, 0),
    ('xgboost', 1, 0, 0),
    ('lightgbm', 1, 0, 0),
    ('catboost', 1, 0, 0),
    ('model_inference', 1, 0, 0),
    ('decision_tree', 1, 0, 0),
    ('random_forest', 1, 0, 0),
    ('svm', 1, 0, 0),
    ('clustering', 1, 0, 0),
    ('anomaly_detection', 1, 0, 0),
    ('reinforcement_learning', 1, 0, 0),
    ('policy_gradient', 1, 0, 0),
    ('q_learning', 1, 0, 0),
    ('deep_q_network', 1, 0, 1),
    ('image_classification', 1, 0, 1),
    ('object_detection', 1, 1, 1),
    ('semantic_segmentation', 1, 1, 1),
    ('instance_segmentation', 1, 1, 1),
    ('natural_language_processing', 1, 0, 0),
    ('bert', 1, 1, 1),
    ('gpt', 1, 1, 1),
    ('transformers', 1, 1, 1),
    ('word_embedding', 1, 1, 0),
    ('feature_extraction', 1, 1, 0),
    ('vgg', 1, 1, 1),
    ('resnet', 1, 1, 1),
    ('inception', 1, 1, 1),
    ('mobilenet', 1, 1, 1),
    ('efficientnet', 1, 1, 1),
    ('auto_ml', 1, 1, 0),
    ('k_means', 1, 0, 0),
    ('pca', 1, 1, 0),
    ('data_visualization', 1, 0, 0),
    ('matplotlib', 1, 0, 0),
    ('seaborn', 1, 0, 0),
    ('plotly', 1, 0, 0),
    ('dashboard', 1, 0, 0),
    ('streamlit', 1, 0, 0),
    ('flask', 1, 0, 0),
    ('django', 1, 0, 0),
    ('api_deployment', 1, 0, 0),
    ('containerization', 1, 1, 0),
    ('model_serving', 1, 0, 0),
    ('data_pipeline', 1, 0, 0),
    ('cloud_computing', 1, 1, 0),
    ('data_security', 1, 0, 0),
    ('data_privacy', 1, 0, 0),
    ('compliance', 1, 0, 0),
    ('data_labeling', 1, 0, 0),
    ('data_cataloging', 1, 0, 0),
    ('etl_process', 1, 1, 0),
    ('data_quality', 1, 0, 0),
    ('data_modeling', 1, 0, 0),
    ('business_intelligence', 1, 0, 0),
    ('data_science', 1, 0, 0),
    ('data_engineering', 1, 0, 0),
    ('data_analysis', 1, 0, 0),
    ('outlier_detection', 1, 0, 0),
    ('neural_architecture_search', 1, 1, 0),
    ('federated_learning', 1, 1, 0),
    ('ensemble_methods', 1, 0, 0),
    ('semi_supervised_learning', 1, 0, 0),
    ('active_learning', 1, 0, 0),
    ('self_supervised_learning', 1, 0, 0),
    ('multi_task_learning', 1, 0, 0),
    ('batch_size', 1, 0, 0),
    ('gradient_boosting', 1, 0, 0),
    ('model_pruning', 1, 1, 0),
    ('neural_style_transfer', 1, 0, 0),
    ('hyperparameter_optimization', 1, 1, 0),
    ('knowledge_distillation', 1, 0, 0),
    ('model_compression', 1, 0, 0),
    ('data_shuffling', 1, 0, 0),
    ('input_pipeline', 1, 1, 0),
    ('memory_management', 1, 0, 0),
    ('multi_class_classification', 1, 0, 0),
    ('binary_classification', 1, 0, 0),
    ('data_mining', 1, 0, 0),
    ('text_classification', 1, 0, 0),
    ('sentiment_analysis', 1, 0, 0),
    ('named_entity_recognition', 1, 0, 0),
    ('text_generation', 1, 0, 0),
    ('text_summarization', 1, 0, 0),
    ('speech_recognition', 1, 0, 0),
    ('chatbot', 1, 0, 0),
    ('voice_assistant', 1, 0, 0),
    ('graph_neural_network', 1, 1, 1),
    ('reinforcement_learning_algorithm', 1, 0, 0),
    ('contextual_bandits', 1, 0, 0),
    ('transferability', 1, 0, 0),
    ('evaluation_protocols', 1, 0, 0),
    ('model_interpretability', 1, 1, 0),
    ('LIME', 1, 0, 0),
    ('SHAP', 1, 1, 0),
    ('feature_map', 1, 0, 0),
    ('residual_connections', 1, 1, 0),
    ('attention_layer', 1, 1, 0),
    ('transformer_encoder', 1, 1, 1),
    ('transformer_decoder', 1, 1, 1),
    ('multi_head_attention', 1, 1, 1),
    ('positional_encoding', 1, 0, 0),
    ('sequence_padding', 1, 0, 0),
    ('sampling_strategy', 1, 0, 0),
    ('class_balance', 1, 0, 0),
    ('feature_engineering', 1, 0, 0),
    ('ensemble_selection', 1, 0, 0),
    ('data_enrichment', 1, 0, 0),
    ('data_integrity', 1, 0, 0),
    ('data_profiling', 1, 0, 0),
    ('data_warehouse', 1, 0, 0),
    ('data_lake', 1, 0, 0),
    ('cloud_storage', 1, 1, 0),
    ('batch_processing', 1, 0, 0),
    ('stream_processing', 1, 1, 0),
    ('real_time_streaming', 1, 1, 0),
    ('data_fusion', 1, 0, 0),
    ('computational_graph', 1, 1, 0),
    ('graph_theory', 1, 0, 0),
    ('maml', 1, 0, 0),
    ('meta_learning', 1, 0, 0),
    ('few_shot_learning', 1, 0, 0),
    ('zero_shot_learning', 1, 0, 0),
    ('data_representation', 1, 0, 0),
    ('data_synthesis', 1, 0, 0),
    ('data_preparation', 1, 0, 0),
    ('data_validation', 1, 0, 0),
    ('performance_benchmarking', 1, 0, 0),
    ('model_selection', 1, 1, 0),
    ('model_retraining', 1, 0, 0),
    ('data_labeling_tool', 1, 0, 0),
    ('data_scientist', 1, 0, 0),
    ('data_engineer', 1, 0, 0),
    ('machine_learning_engineer', 1, 0, 0),
    ('model_versioning', 1, 0, 0),
    ('hyperparameter_tuning_tool', 1, 1, 0),
    ('experiment_tracking', 1, 0, 0),
    ('software_development_lifecycle', 1, 0, 0),
    ('version_control', 1, 0, 0),
    ('devops', 1, 0, 0),
    ('mlops', 1, 1, 0),
    ('pipeline_automation', 1, 1, 0),
    ('feedback_loop', 1, 0, 0),
    ('model_feedback', 1, 0, 0),
    ('data_security_compliance', 1, 0, 0),
    ('data_protection', 1, 0, 0),
    ('algorithmic_bias', 1, 0, 0),
    ('model_ethics', 1, 0, 0),
    ('explainable_ai', 1, 1, 0),
    ('transparent_ml', 1, 0, 0),
    ('cloud_infrastructure', 1, 1, 0),
    ('big_data', 1, 1, 0),
    ('data_scalability', 1, 1, 0),
    ('image_segmentation', 1, 0, 0),
    ('semantic_segmentation', 1, 1, 1),
    ('instance_segmentation', 1, 1, 1),
    ('image_classification', 1, 0, 0),
    ('object_detection', 1, 1, 0),
    ('style_transfer', 1, 0, 0),
    ('data_augmentation_techniques', 1, 0, 0),
    ('text_embedding', 1, 0, 0),
    ('feature_selection', 1, 0, 0),
    ('time_series_analysis', 1, 0, 0),
    ('anomaly_detection', 1, 0, 0),
    ('dimensionality_reduction', 1, 0, 0),
    ('pca', 1, 0, 0),
    ('t_sne', 1, 0, 0),
    ('vae', 1, 0, 0),
    ('autoencoder', 1, 0, 0),
    ('deep_fakes', 1, 0, 0),
    ('data_cleansing', 1, 0, 0),
    ('data_normalization', 1, 0, 0),
    ('categorical_encoding', 1, 0, 0),
    ('target_encoding', 1, 0, 0),
    ('label_encoding', 1, 0, 0),
    ('word_embedding', 1, 0, 0),
    ('fasttext', 1, 0, 0),
    ('word2vec', 1, 0, 0),
    ('glove', 1, 0, 0),
    ('contextual_word_embeddings', 1, 0, 0),
    ('transformer_model', 1, 1, 1),
    ('bert', 1, 1, 1),
    ('gpt', 1, 1, 1),
    ('xlmr', 1, 1, 1),
    ('ner_model', 1, 1, 0),
    ('ml_model_deployment', 1, 0, 0),
    ('api_integration', 1, 0, 0),
    ('cloud_ml_services', 1, 1, 0),
    ('distributed_training', 1, 1, 1),
    ('hyperparameter_sweeping', 1, 1, 0),
    ('data_slicing', 1, 0, 0),
    ('data_summarization', 1, 0, 0),
    ('text_vectorization', 1, 0, 0),
    ('sparse_data_handling', 1, 0, 0),
    ('model_ensembling', 1, 0, 0),
    ('feature_importance', 1, 0, 0),
    ('gradient_descent', 1, 0, 0),
    ('stochastic_gradient_descent', 1, 0, 0),
    ('adam_optimizer', 1, 0, 0),
    ('momentum_optimizer', 1, 0, 0),
    ('learning_rate_scheduler', 1, 0, 0),
    ('regularization_techniques', 1, 0, 0),
    ('dropout_rate', 1, 0, 0),
    ('early_stopping', 1, 0, 0),
    ('learning_rate_finder', 1, 0, 0),
    ('cross_entropy_loss', 1, 0, 0),
    ('mean_squared_error', 1, 0, 0),
    ('binary_crossentropy', 1, 0, 0),
    ('multi_class_crossentropy', 1, 0, 0),
    ('f1_score', 1, 0, 0),
    ('precision_recall_curve', 1, 0, 0),
    ('roc_auc', 1, 0, 0),
    ('accuracy_score', 1, 0, 0),
    ('training_curve', 1, 0, 0),
    ('overfitting_detection', 1, 0, 0),
    ('data_partitioning', 1, 0, 0),
    ('train_test_split', 1, 0, 0),
    ('holdout_validation', 1, 0, 0),
    ('k_fold_cross_validation', 1, 0, 0),
    ('stratified_sampling', 1, 0, 0),
    ('pipeline_management', 1, 0, 0),
    ('model_registry', 1, 0, 0),
    ('data_access_management', 1, 0, 0),
    ('visualization_tools', 1, 0, 0),
    ('data_storytelling', 1, 0, 0),
    ('interactive_visualization', 1, 0, 0),
    ('dashboard_creation', 1, 0, 0),
    ('real_time_dashboard', 1, 0, 0),
    ('reporting_tools', 1, 0, 0),
    ('automated_reporting', 1, 0, 0),
    ('business_intelligence', 1, 0, 0),
    ('model_update_strategy', 1, 0, 0),
    ('data_collection_strategy', 1, 0, 0),
    ('data_pipeline', 1, 0, 0),
    ('scraping_tools', 1, 0, 0),
    ('data_migration', 1, 0, 0),
    ('data_sharing_protocol', 1, 0, 0),
    ('compliance_standards', 1, 0, 0),
    ('data_retention_policy', 1, 0, 0),
    ('model_auditing', 1, 0, 0),
    ('feedback_analysis', 1, 0, 0)
]


# Create the dataset from the unique keywords
data = [[keyword, cpu, gpu, tpu] for keyword, cpu, gpu, tpu in keywords]

# Create a DataFrame
df = pd.DataFrame(data, columns=['Keyword', 'CPU', 'GPU', 'TPU'])

# Save to Excel
df.to_excel('resource_allocation_dataset.xlsx', index=False)
